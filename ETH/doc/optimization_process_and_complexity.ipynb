{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"mathmacros\" style=\"display:none;\">\n",
    "$\\def\\bra#1{\\mathinner{\\langle{#1}|}}\n",
    "\\def\\ket#1{\\mathinner{|{#1}\\rangle}}\n",
    "\\def\\braket#1{\\mathinner{\\langle{#1}\\rangle}}\n",
    "\\newcommand{\\mdef}{\\overset{\\mathrm{def}}{=}}\n",
    "\\newcommand{\\bm}{\\mathbf}\n",
    "\\newcommand{\\inv}[1]{#1^{-1}}   % Inverse Matrix\n",
    "\\newcommand{\\invt}[1]{#1^{-T}}  % Inverse Transposed Matrix\n",
    "\\renewcommand{\\nl}{\\\\&\\phantom{{}={}}}% Newline In aligned equations\n",
    "\\newcommand{\\pfr}[2]{\\frac{\\pp #1}{\\pp #2}}      % Partial derivative\n",
    "\\newcommand{\\dfr}[2]{\\frac{\\dd #1}{\\dd #2}}      % Total derivative\n",
    "\\newcommand{\\pp}{\\partial}\n",
    "\\DeclareMathOperator{\\Var}{Var}\n",
    "\\DeclareMathOperator{\\det}{det}\n",
    "\\DeclareMathOperator{\\tr}{tr}\n",
    "\\DeclareMathOperator{\\sgn}{sgn}\n",
    "\\DeclareMathOperator{\\adj}{adj}\n",
    "\\DeclareMathOperator{\\ii}{i}\n",
    "\\DeclareMathOperator{\\dd}{d}\n",
    "\\DeclareMathOperator{\\rhs}{RHS}\n",
    "\\DeclareMathOperator{\\lhs}{LHS}\n",
    "\\newcommand{\\nl}{\\\\&\\phantom{={}}}\n",
    "\\DeclareMathOperator{\\E}{E}\n",
    "\\DeclareMathOperator{\\Cov}{Cov}\n",
    "\\DeclareMathOperator{\\Beta}{B}\n",
    "\\DeclareMathOperator{\\Bdist}{Beta}$\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial state\n",
    "Initially we have a product density matrix $\\rho=\\bigotimes \\rho_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization steps\n",
    "\n",
    "Suppose $h$ is a Hermitian matrix, then $U=e^{ih}$ is unitary. The optimization is iteratively applying $U_i=e^{ih_i}$ at step $i$ to give a better $$\\rho_{i+1}=e^{ih_i}\\rho_i e^{-ih_i}$$\n",
    "to minimize\n",
    "$$f(h_i)=\\tr[H^2U_i\\rho_i U_i^+]-\\tr^2[HU_i\\rho_i U_i^+]$$\n",
    "\n",
    "The optimization at each step is using gradient $M=\\nabla_h f$ to give a descent direction. Then consider $h_i=xM$, we can find first and second order derivative over $x$, which gives an estimation on best step size $x=-f'/f''$.\n",
    "\n",
    "This process is similar for optimization of local Unitaries\n",
    "\n",
    "#### Approximation to $\\exp$\n",
    "In every optimization step, once we have an $h$ we should apply $\\exp(i h)$ to operators. If we replace the exact `scipy.linalg.expm` with pade approximation $$e^x\\approx \\frac{1+x/2}{1-x/2},$$ the optimization steps are much faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time complexity\n",
    "Parameters: Depth $D$ of circuit, length $L$ of chain. General conclusions:\n",
    "+ Number of local $U$ is $N_u=DL/l$\n",
    "+ Local unitaries are $m\\times m$, where $m=2^l=4$ \n",
    "+ Dense matrix is $n\\times n$, where $n=2^L$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense optimization\n",
    "We have dense $\\rho$ and $H$ with dimension $n\\times n$. The initial contraction can be amortized to every block, and during one contraction cycle there are $N_u$ blocks to contract. In every step, the time of transform a pair of slots is proportional to applying single $U$ to huge matrix, i.e. $mn^2$. Actually, we will apply four times($\\rho$ twice and $H$ twice). Contract to hole is also $mn^2$. Time complexity for one cycle is\n",
    "$$\\Theta(mn^2N_u)=\\Theta(2^{2L+l}DL/l)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse optimization\n",
    "We make the assumption that $L>D$.\n",
    "#### MPO\n",
    "Except for the MPO part, it is similar to dense optimization, but rotated by $\\pi/2$. There are $D-1$ free 2-legs maintained for every half of the system, and one M-leg for the MPO. The dense matrix maintained has dimension $2^{2(D-1)}M$. Similar to the analysis in dense optimization, the time complexity for one cycle is\n",
    "$$\\Theta(2^{2(D-1)}MmN_u)$$\n",
    "\n",
    "The speed boost of sparse mpo is $k\\approx 4^{L-D}$. If $L$ is larger than $D$, this is a win!\n",
    "\n",
    "#### ~~Cones method~~\n",
    "It seems that cone method has weak overlapping between different terms. We decompose $H^2$ into $L^2$ terms and later collect effect of each one. Considering dependency of each term, it only depends on $LD$ terms. Naively, for each term the contraction is proportional to $D^2$. Consider full contraction for a single hole, the time is $LDD^22^Dm$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is effect of optimization order?\n",
    "Can not easily predict..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
